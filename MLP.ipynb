{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exploration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGDkQg03-kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SThknWY5oD7",
        "colab_type": "code",
        "outputId": "0daf74fd-9ef6-4462-e1c1-fe7ecc536e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEJ7MRRR6XV3",
        "colab_type": "code",
        "outputId": "21d040a0-5201-4114-a6ce-30e6f7dff3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "#Let us show some of the training images, for fun.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(1)))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  car\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERTsQiSCgl2IRFCwC5EICnYhEuH/AisH4GNT/lu8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkKhhsWWPyV9",
        "colab_type": "code",
        "outputId": "131e579f-ec71-4a34-a555-a8218eea57fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#getting the x(2d matrix of 50000*3072, input images), and y(1*3072, output label);\n",
        "tmpTrain = trainloader.dataset.data # shape of 50000*32*32*3 need to transform to 50000*3072\n",
        "x,y1,y2,y3 = tmpTrain.shape\n",
        "trainX = np.zeros([x, y1*y2*y3])\n",
        "tmpTrainY = trainloader.dataset.targets\n",
        "trainY = np.zeros([len(tmpTrainY), len(classes)])\n",
        "for i in range(len(tmpTrainY)):\n",
        "  trainY[i][tmpTrainY[i]] = 1\n",
        "tmpTest = testloader.dataset.data # shape of 10000*32*32*3 need to transform to 10000*3072\n",
        "xx, y4, y5, y6 = tmpTest.shape\n",
        "testY = testloader.dataset.targets\n",
        "testX = np.zeros([xx, y4*y5*y6])\n",
        "for i in range(x):\n",
        "  trainX[i] = tmpTrain[i].flatten()\n",
        "\n",
        "trainX = trainX / np.linalg.norm(trainX) \n",
        "for j in range(xx):\n",
        "  testX[j] = tmpTest[j].flatten()\n",
        "\n",
        "testX = testX / np.linalg.norm(testX)\n",
        "\n",
        "print(\"the shape of matrix trainX\" + str(trainX.shape))\n",
        "print(\"the size of trainY \" + str(trainY.shape))\n",
        "print(\"the shape of matrix testX\" + str(testX.shape))\n",
        "print(\"the size of testY \" + str(len(testY)))\n",
        "print(trainX[15])\n",
        "\n",
        "\n"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the shape of matrix trainX(50000, 3072)\n",
            "the size of trainY (50000, 10)\n",
            "the shape of matrix testX(10000, 3072)\n",
            "the size of testY 10000\n",
            "[5.90271027e-05 9.91655325e-05 1.36352607e-04 ... 9.56239063e-05\n",
            " 1.09200140e-04 1.19234747e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rFqSD03GiWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#activation functions\n",
        "\n",
        "def relu(x):\n",
        "  N, D = x.shape\n",
        "  ans = np.zeros([N,D])\n",
        "  for i in range(N):\n",
        "    for j in range(D):\n",
        "      if x[i][j] > 0:\n",
        "        ans[i][j] = x[i][j]\n",
        "      else:\n",
        "        ans[i][j] = 0\n",
        "  return ans\n",
        "\n",
        "def sigmoid(x):\n",
        "  N, D = x.shape\n",
        "  ans = np.zeros([N,D])\n",
        "  for i in range(N):\n",
        "    for j in range(D):\n",
        "      try:\n",
        "        ans[i][j] = 1/(1+math.exp(-x[i][j]))\n",
        "      except OverflowError:\n",
        "        if(x[i][j])>0:\n",
        "          ans[i][j] = 1\n",
        "        else:\n",
        "          ans[i][j] = 0\n",
        "  return ans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5kBvCH1PwjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define weights for different layers, put them in a list called Ws, each weight has a shape of size(l-1)*size(l)\n",
        "layerNumber = [1024,100] #number of hidden layers and number of nodes in each layer\n",
        "AV = sigmoid #activation function that we use \n",
        "Ws = []\n",
        "N,D = trainX.shape\n",
        "start = D\n",
        "N,DD =trainY.shape\n",
        "end = layerNumber[0]\n",
        "w = np.random.randn(start, end)*.01\n",
        "for i in range(start):\n",
        "  for j in range(end):\n",
        "    w[i][j] = 0\n",
        "Ws.append(w)\n",
        "for i in range(len(layerNumber)):\n",
        "  start = layerNumber[i]\n",
        "  if i+1 == len(layerNumber):\n",
        "    end = DD\n",
        "  else:\n",
        "    end = layerNumber[i+1]\n",
        "  w = np.random.randn(start, end)*.01\n",
        "  Ws.append(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8eu-zmmTTA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Zs = [] #hidden layers\n",
        "\n",
        "def getYhead(X):\n",
        "  Y = []\n",
        "  N,D = X.shape\n",
        "  Zs.clear()\n",
        "  for layer in layerNumber:\n",
        "    Zs.append(np.zeros([N,layer]))\n",
        "  Yhead = np.zeros([N, len(classes)])\n",
        "  tmp = X\n",
        "  for i in range(len(Ws)-1):\n",
        "    NN,DD = tmp.shape\n",
        "    tmp = AV(np.dot(tmp, Ws[i])) #Doing activation function for the Zs in layer\n",
        "    Zs[i] = tmp\n",
        "  Y = sigmoid(np.dot(tmp, Ws[len(Ws)-1])) #Doing sigmoid for final layer since it is binary classification\n",
        "  return Y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUzlEIeXWltp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cost of one training result\n",
        "def cost(Y1, Y2):\n",
        "  total = 0.0\n",
        "  for i in range(len(Y1)):\n",
        "    value = (Y1[i]-Y2[i])*(Y1[i]-Y2[i])\n",
        "    total = total + value\n",
        "  return total\n",
        "\n",
        "\n",
        "#Average cost of all training result\n",
        "def averageCost(Y1, Y2):\n",
        "  N,D = Y1.shape\n",
        "  total = 0.0\n",
        "  for i in range(N):\n",
        "    total = total + cost(Y1[i],Y2[i])\n",
        "  return total/N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0cngWwPgyDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "26123018-289b-4674-a0e8-d3f90ef318a8"
      },
      "source": [
        "\n",
        "\n",
        "def gradient(X, Y):\n",
        "  N,D = X.shape\n",
        "  Yh = getYhead(X)\n",
        "  print(\"Average cost so far \" + str(averageCost(Yh, Y)))\n",
        "  dY = 2*(Yh - Y)\n",
        "  dZnext =dY\n",
        "  WsReversed = Ws.copy()\n",
        "  ZsReversed = Zs.copy()\n",
        "  WsReversed.reverse() #reverse them since we need to calculate the dw from last layer to the first layer\n",
        "  ZsReversed.reverse()\n",
        "  dWs =[]\n",
        "  w = WsReversed[0]\n",
        "  z = ZsReversed[0]\n",
        "  dW = np.dot(z.T, dZnext*Yh*(1-Yh))\n",
        "  #Probably the problem come from here, I am trying to calculate the dWeight between last hidden layer and final layer\n",
        "  #now z is the last hidden layer, Yh is the final answer, in the video, derivative of w = al-1*(derivative of sigmoid)*dy\n",
        "  #al-1 is last hidden layer, Yh*(1-Yh) is the derivative of sigmoid, and dzNext is dy, however if Yh is all zero them dW\n",
        "  #would be zero and if will keeps like that, and I was like what???\n",
        "  dZnext = np.dot(dZnext*Yh*(1-Yh), w.T)\n",
        "  dWs.append(dW)\n",
        "  for i in range(1, len(WsReversed)):\n",
        "    w = WsReversed[i]\n",
        "    zPrevious = ZsReversed[i-1]\n",
        "    if i >= len(ZsReversed):\n",
        "      z = X.copy()\n",
        "    else:\n",
        "      z = ZsReversed[i]\n",
        "    Zn, Zd = zPrevious.shape\n",
        "    dW = np.dot(z.T, dZnext*zPrevious*(1-zPrevious))\n",
        "    dZnext = np.dot(dZnext*zPrevious*(1-zPrevious), w.T)\n",
        "    dWs.append(dW)\n",
        "  dWs.reverse()\n",
        "  return dWs\n",
        "\n",
        "def fit(X, Y, lr, eps, bsize):\n",
        "  N,D = X.shape\n",
        "  dW = np.inf*np.ones_like(Ws[len(Ws)-1])\n",
        "  while np.linalg.norm(dW) > eps:\n",
        "    minibatch = np.random.randint(N, size=(bsize))\n",
        "    g = gradient(X[minibatch,:], Y[minibatch,:])\n",
        "    for i in range(len(Ws)):\n",
        "      Ws[i] = Ws[i]-lr*g[i]\n",
        "    dW = g[len(Ws)-1]\n",
        "\n",
        "def getBiggestY(Y): \n",
        "  N,D = Y.shape\n",
        "  result = np.zeros([N])\n",
        "  for i in range(N):\n",
        "    biggest = 0\n",
        "    biggestNum = 0\n",
        "    for j in range(D):\n",
        "      if Y[i][j]>biggest:\n",
        "        biggestNum = j\n",
        "        biggest = Y[i][j]\n",
        "      result[i] = j\n",
        "  return result\n",
        "\n",
        "def predict(testX, testY):\n",
        "  print(\"predicting ...\")\n",
        "  yHead = getYhead(testX)\n",
        "  yResult = getBiggestY(yHead)\n",
        "  totalRight = 0.0\n",
        "  for i in range(len(testY)):\n",
        "    if(yResult[i] == testY[i]):\n",
        "      totalRight = totalRight+1\n",
        "  return totalRight/len(testY)\n",
        "\n",
        "\n",
        "fit(trainX, trainY, 0.1, 1e-09, 1000)\n",
        "print(predict(testX, testY))\n"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average cost so far 1.0\n",
            "predicting ...\n",
            "0.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}